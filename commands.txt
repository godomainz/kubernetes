kubectl cluster-info
kubectl get nodes
kubectl get namespaces

kubectl run nginx --image nginx
kubectl run mosquito --image nginx
kubectl describe pods
kubectl describe pod nginx
kubectl get pods
kubectl get pods -o wide
kubectl create -f filename.yml

--------------------------------------------------------------------------------------------------------------------------------------------
# Imparative commands
kubectl run nginx-pod --image=nginx:alpine
kubectl run redis --image=redis:alpine -l tier=db (Sets the lable tier=db)
kubectl expose pod redis --port=6379 --name redis-service (Create a service redis-service to expose the redis application within the cluster on port 6379.)

## Create a deployment named webapp using the image kodekloud/webapp-color with 3 replicas
kubectl create deployment webapp --image=kodekloud/webapp-color
kubectl scale deployment/webapp --replicas=3

## Create a new pod called custom-nginx using the nginx image and expose it on container port 8080
kubectl run custom-nginx --image=nginx --port=8080

## Create a new namespace called dev-ns.

## Create a new deployment called redis-deploy in the dev-ns namespace with the redis image. It should have 2 replicas.
step 1: Create the deployment YAML file
kubectl create deployment redis-deploy --image redis --namespace=dev-ns --dry-run=client -o yaml > deploy.yaml
Step 2: Edit the YAML file and add update the replicas to 2
Step 3: Run kubectl apply -f deploy.yaml to create the deployment in the dev-ns namespace.
You can also use kubectl scale deployment or kubectl edit deployment to change the number of replicas once the object has been created.

## Create a pod called httpd using the image httpd:alpine in the default namespace. 
Next, create a service of type ClusterIP by the same name (httpd). 
The target port for the service should be 80 ##
kubectl run httpd --image=httpd:alpine --port=80 --expose



--------------------------------------------------------------------------------------------------------------------------------------------


kubectl delete service kubernetes-bootcamp
kubectl delete pod kubernetes-bootcamp-6f6656d949-7smv7
kubectl delete deployment kubernetes-bootcamp

kubectl get replicationcontroller
kubectl get replicaset

kubectl replace -f filename.yml
kubectl scale --replicas=6 -f filename.yml

kubectl scale --replicas=6 $TYPE $NAME
kubectl scale --replicas=6 replicaset myapp-replicaset

kubectl describe replicaset

kubectl get all
kubectl get deployments
kubectl get replicationcontrollers
kubectl get replicasets
kubectl describe deployment

kubectl create -f 4_Deployment/deployment-definition.yml
kubectl create -f 4_Deployment/deployment-definition.yml --record


#Rolling updates

kubectl rollout status deployment/myapp-deployment
kubectl rollout history deployment/myapp-deployment

kubectl apply -f deployment-definition.yml
kubectl apply -f deployment-definition.yml --record

kubectl set image deployment/myapp-deployment $ANYNAME=$IMAGEVALUE
kubectl set image deployment/myapp-deployment nginx-container=nginx:1.9.1

kubectl rollout undo deployment/myapp-deployment

# Services
kubectl get services

# Configure kubectl proxy

kubectl proxy
http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/

kubectl create serviceaccount dashboard-admin-sa
kubectl create clusterrolebinding dashboard-admin-sa --clusterrole=cluster-admin --serviceaccount=default:dashboard-admin-sa
kubectl get secrets
kubectl describe secret dashboard-admin-sa-token-kw7vn(type the correct name)

# Calling a service in another namespace
db-service.dev.svc.cluster.local
db-service = Service name
dev = Namespace
svc = Service
cluster.local = default domain of kubernetes cluster

# List pods in another namespace
kubectl get pods --namespace=kube-system

# create pods in another namespace
kubectl create -f filename.yml --namespace=dev

# create namespace
kubectl create namespace $NAME
kubectl create namespace dev

# Switch to a namespace permanently
kubectl config set-context $(kubectl config current-context) --namespace=dev

# View pods in all namespaces
kubectl get pods --all-namespaces

# kubectl shell autocomplete
source <(kubectl completion bash)
echo "source <(kubectl completion bash)" >> ~/.bashrc

# Create ConfigMap (Imparetive)
kubectl create configmap <config-name> --from-literal=<key>=<value>
kubectl create configmap app-config --from-literal=APP_COLOR=blue --from-literal=APP_MOD=prod


kubectl create configmap <config-name> --from-file=<path-to-file>
kubectl create configmap app-config --from-file=app_config.properties
 
# Create ConfigMap (Declarative)
kubectl create -f filename.yml 

# View ConfigMaps
kubectl get configmaps
kubectl describe configmaps

# Create secrets (Imparetive)

kubectl create secret generic <secret-name> --from-literal=<key>=<value>
kubectl create secret generic app-secret --from-literal=DB_Host=mysql 
kubectl create secret generic app-secret --from-literal=DB_Host=mysql --from-literal=DB_User=root --from-literal=DB_password=paswrd
kubectl create secret generic db-secret --from-literal=DB_Host=sql01 --from-literal=DB_User=root --from-literal=DB_Password=password123


kubectl create secret generic <secret-name> --from-file=<path-to-file>
kubectl create secret generic app-secret --from-file=app_secret.properties


# Create secrets (Declarative)
kubectl create -f filename.yml

# View secrets
kubectl get secrets
kubectl describe secrets
kubectl describe secret $SECRET_NAME

kubectl get secret $SECRET_NAME -o yaml

# Use these commands to convert plain text to base64 value
echo -n 'mysql' | base64
echo -n 'root' | base64
echo -n 'paswrd' | base64

# Decode secret
echo -n 'bXlzcWw=' | base64 --decode

# Executing a command in pod
kubectl exec ubuntu-sleeper whoami (depreciated)
kubectl exec ubuntu-sleeper -- whoami
kubectl exec -it ubuntu-sleeper -- /bin/bash

# Create Service account
kubectl create serviceaccount dashboard-sa
kubectl get serviceaccount
kubectl describe serviceaccount dashboard-sa

# Taints - Node
kubectl taint nodes node-name key=value:taint-effect

taint-effect --> NoSchedule | PreferNoSchedule | Noexecute

kubectl taint nodes node1 app=blue:NoSchedule
kubectl describe node ubuntu | grep Taint
kubectl taint nodes node01 spray=mortein:NoSchedule

# Deleting a taint on a node
kubectl taint nodes master node-role.kubernetes.io/master:NoSchedule-

# Lable Node
kubectl label nodes <node-name> <label-key>=<label-value>
kubectl label nodes node1 color=blue


kubectl create deployment blue --image=nginx
kubectl scale deployment blue --replicas=6

kubectl describe pod -n elastic-stack
kubectl -n elastic-stack exec -it app cat /log/app.log
kubectl get pod simple-webapp-2 -o yaml > mypod.yaml


#Logging

kubectl logs $CONTAINER_NAME
kubectl logs webapp-1

kubectl logs -f $POD_NAME
kubectl logs -f $POD_NAME $CONTAINE_RNAME
kubectl logs -f webapp-2 simple-webapp

# Monitoring
kubectl top node
kubectl top pod

# Labels and selectors
kubectl get pods --selector app=App1
kubectl get all --selector env=prod
kubectl get pod --selector env=prod,bu=finance,tier=frontend
kubectl get pods -l k8s-app=kube-dns -n kube-system

# Jobs
kubectl create -f job-definition.yaml
kubectl get jobs
kubectl delete job $JOB_NAME

# CronJob
kubectl get cronjobs

# Network policies
kubectl get networkpolicy
kubectl describe networkpolicy



# Ingress
kubectl describe ingress ingress-wear-watch

kubectl get all --all-namespaces
kubectl get Ingress --all-namespaces
kubectl describe ingress ingress-wear-watch --namespace app-space
kubectl edit ingress ingress-wear-watch --namespace app-space
kubectl get deploy --all-namespaces

kubectl create namespace ingress-space
kubectl create configmap nginx-configuration --namespace ingress-space
kubectl create serviceaccount ingress-serviceaccount --namespace ingress-space
kubectl get roles,rolebindings --namespace ingress-space
kubectl expose deployment -n ingress-space ingress-controller --type=NodePort --port=80 --name=ingress --dry-run -o yaml >ingress.yaml

# Persistant volumes
kubectl get pv

# Persistant volume claim
kubectl get pvc
kubectl delete pvc NAME

# Troubleshoot
https://stackoverflow.com/questions/34878574/kubernetes-mysql-chown-operation-not-permitted

# namespaces
kubectl get namespace
kubectl config set-context --current --namespace=<insert-namespace-name-here>
# Validate it
kubectl config view --minify | grep namespace:

kubectl get pods --all-namespaces

# General commands
systemctl daemon-reload
systemctl restart kubelet
kubectl cluster-info
kubectl version

# enabling PodPresets
sudo vim /etc/kubernetes/manifests/kube-apiserver.yaml
add/edit these lines and save
- --enable-admission-plugins=NodeRestriction,PodPreset
- --runtime-config=settings.k8s.io/v1alpha1=true

# PodPresets
kubectl get podpresets

# Auto scaling
kubectl get hpa

# Postgres Operator
https://github.com/CrunchyData/postgres-operator

Install the pgo Client
curl https://raw.githubusercontent.com/CrunchyData/postgres-operator/v4.4.1/installers/kubectl/client-setup.sh > client-setup.sh
chmod +x client-setup.sh
./client-setup.sh

Before running pgo create cluster create command run PersistantVolumeClaim files --> postgres-operator-pvc.yaml,postgres-operator-pvc-cluster.yaml,postgres-operator-pvc-repo.yaml

pgo create cluster mycluster --namespace pgo
created cluster: mycluster
workflow id: 38dd13e0-4082-44d8-b296-b721d51297e2
database name: mycluster
users:
	username: testuser password: U6cYxi/PPJ-|/T57zX.iSp4w

pgo delete cluster mycluster --namespace pgo

pgo show cluster all

pgo show cluster --all --namespace pgo


# Networking - Switching and Routing commands
ip link
ip addr add 192.168.1.10/24 dev eth0
route
ip route add 192.1668.2.0/24 via 192.168.1.1
ip route add default via 192.168.2.1
cat /proc/sys/net/ipv4/ip_forward
echo 1 > /proc/sys/net/ipv4/ip_forward

cat /etc/sysctl.conf
echo net.ipv4.ip_forward=1 > /etc/sysctl.conf

# Networking - dns
cat /etc/hosts
hostname
cat /etc/resolv.conf
nameserver 8.8.8.8
echo  nameserver 8.8.8.8 > /etc/resolv.conf
search mycompany.com
nslookup google.com
dig google.com


# Networking - namespaces
ip netns list

## creating network namespaces
ip netns add red

ip netns exec red ip link
ip -n red link

arp
ip netns exec red arp

## creating connected virtual network interfaces 
ip link add veth-red type veth peer name veth-blue

## connecting virtual network interfaces to network namespaces 
ip link set veth-red netns red
ip link set veth-blue netns blue

## adding IP addresses to virtual network interfaces
ip -n red addr add 192.168.15.1 dev veth-red
ip -n blue addr add 192.168.15.2 dev veth-blue

## Bring up virtual network interfaces
ip -n red link set veth-red up
ip -n blue link set veth-blue up

## Linux bridge (virtual Switch)
ip link add v-net-0 type bridge
ip link set dev v-net-0 up

## delete virtual network interfaces
ip -n red link del veth-red

ip link add veth-red type veth peer name veth-red-br
ip link add veth-blue type veth peer name veth-blue-br

## Connect virtual network interfaces to virtual Switch
ip link set veth-red netns red
ip link set veth-red-br master v-net-0
ip link set veth-blue netns blue
ip link set veth-blue-br master v-net-0
ip -n red addr add 192.168.15.1 dev veth-red
ip -n blue addr add 192.168.15.2 dev veth-blue
ip -n red link set veth-red up
ip -n blue link set veth-blue up
ip addr add 192.168.15.5/24 dev v-net-0
ip netns exec blue ip route add 192.168.1.0/24 via 192.168.15.5

iptables -t nat -A POSTROUTING -s 192.168.15.0/24 -j MASQUERADE
ip netns exec blue ip route add default via 192.168.15.5

iptables -t nat -A PREROUTING --dport 80 --to-destination 192.168.15.2:80 -j DNAT

iptables -nvL -t nat
ifconfig -a | grep -Po 'ether \K.*$'

cat /proc/sys/net/ipv4/ip_forward
netstat -plnt
arp node01
ip route show default
kubectl get nodes -o wide
netstat -anp | grep etcd
sudo sysctl net.bridge.bridge-nf-call-iptables=1

ip addr show weave

iptables -L -t net | grep db-service
cat /var/log/kube-proxy.log


ps -aux | grep kubelet

kubectl -n kube-system describe deployments.apps coredns | grep -A2 Args | grep Corefile
kubectl describe configmap coredns -n kube-system


# Istio getting started
https://istio.io/latest/docs/setup/getting-started/


# Virtual Services
kubectl get vs
kubectl get virtualservices

# Destination Rules
kubectl get destinationrules
kubectl get dr

kubectl api-resources
kubectl cluster-info
kubectl get apiservices

